<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Configuring a Stream Application &mdash; Streamiz.Kafka.Net  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=5929fcd5"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Threading model" href="threading-model.html" />
    <link rel="prev" title="Overview" href="overview.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Streamiz.Kafka.Net
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Streamiz.Kafka.Net</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Configuring a Stream Application</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#required-configuration-parameters">Required configuration parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#applicationid">ApplicationId</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bootstrapservers">BootstrapServers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#optional-configuration-parameters">Optional configuration parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#guarantee">Guarantee</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defaulttimestampextractor">DefaultTimestampExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defaultkeyserdes">DefaultKeySerDes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#defaultvalueserdes">DefaultValueSerDes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#numstreamthreads">NumStreamThreads</a></li>
<li class="toctree-l3"><a class="reference internal" href="#clientid">ClientId</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transactionalid">TransactionalId</a></li>
<li class="toctree-l3"><a class="reference internal" href="#transactiontimeout">TransactionTimeout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#commitintervalms">CommitIntervalMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pollms">PollMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxpollrecords">MaxPollRecords</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxpollrestoringrecords">MaxPollRestoringRecords</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxtaskidlems">MaxTaskIdleMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#maxpollintervalms">MaxPollIntervalMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bufferedrecordsperpartition">BufferedRecordsPerPartition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#innerexceptionhandler">InnerExceptionHandler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deserializationexceptionhandler">DeserializationExceptionHandler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#productionexceptionhandler">ProductionExceptionHandler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logger">Logger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#configuring-log4net">Configuring log4net</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#followmetadata">FollowMetadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statedir">StateDir</a></li>
<li class="toctree-l3"><a class="reference internal" href="#replicationfactor">ReplicationFactor</a></li>
<li class="toctree-l3"><a class="reference internal" href="#windowstorechangelogadditionalretentionms">WindowStoreChangelogAdditionalRetentionMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#offsetcheckpointmanager">OffsetCheckpointManager</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rocksdbconfighandler">RocksDbConfigHandler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metricsintervalms">MetricsIntervalMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metricsreporter">MetricsReporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exposelibrdkafkastats">ExposeLibrdKafkaStats</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metricsrecording">MetricsRecording</a></li>
<li class="toctree-l3"><a class="reference internal" href="#starttaskdelayms">StartTaskDelayMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#basicauthuserinfo">BasicAuthUserInfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="#basicauthcredentialssource">BasicAuthCredentialsSource</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schemaregistryrequesttimeoutms">SchemaRegistryRequestTimeoutMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schemaregistrymaxcachedschemas">SchemaRegistryMaxCachedSchemas</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schemaregistryurl">SchemaRegistryUrl</a></li>
<li class="toctree-l3"><a class="reference internal" href="#autoregisterschemas">AutoRegisterSchemas</a></li>
<li class="toctree-l3"><a class="reference internal" href="#subjectnamestrategy">SubjectNameStrategy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#kafka-consumers-and-producer-configuration-parameters">Kafka consumers and producer configuration parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sample-configuration-implementation">Sample configuration implementation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="threading-model.html">Threading model</a></li>
<li class="toctree-l1"><a class="reference internal" href="stateless-processors.html">Stateless processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="stateful-processors.html">Stateful processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="stores.html">State stores</a></li>
<li class="toctree-l1"><a class="reference internal" href="topology-test-driver.html">Test topology driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitoring.html">Monitoring Stream Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="async-processing.html">Asynchronous processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="processor-api.html">Processor API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Streamiz.Kafka.Net</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Configuring a Stream Application</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/stream-configuration.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="configuring-a-stream-application">
<h1>Configuring a Stream Application<a class="headerlink" href="#configuring-a-stream-application" title="Link to this heading">ÔÉÅ</a></h1>
<p>Stream configuration options must be configured before using Streams. You can configure KafkaStream by specifying parameters in a <code class="docutils literal notranslate"> <span class="pre">IStreamConfig</span></code> instance.</p>
<p><code class="docutils literal notranslate"> <span class="pre">IStreamConfig</span></code> is an interface which defines all the parameters necessary for the proper functioning of a stream. You can therefore create your own implementation of your configuration.</p>
<p>You have a default implementation in Streamiz Kafka .Net package (aka <code class="docutils literal notranslate"> <span class="pre">StreamConfig</span></code>)</p>
<section id="required-configuration-parameters">
<h2>Required configuration parameters<a class="headerlink" href="#required-configuration-parameters" title="Link to this heading">ÔÉÅ</a></h2>
<section id="applicationid">
<h3>ApplicationId<a class="headerlink" href="#applicationid" title="Link to this heading">ÔÉÅ</a></h3>
<p>(Required) The application ID. Each stream processing application must have a unique ID. The same ID must be given to all instances of the application. It is recommended to use only alphanumeric characters, . (dot), - (hyphen), and _ (underscore). Examples: ‚Äúhello_world‚Äù, ‚Äúhello_world-v1.0.0‚Äù</p>
<p>This ID is used in the following places to isolate resources used by the application from others:</p>
<p>As the default Kafka consumer and producer client.id prefix
As the Kafka consumer group.id for coordination
As the name of the subdirectory in the state directory (cf. state.dir)
As the prefix of internal Kafka topic names
Tip:
When an application is updated, the application.id should be changed unless you want to reuse the existing data in internal topics and state stores. For example, you could embed the version information within application.id, as my-app-v1.0.0 and my-app-v1.0.2.</p>
</section>
<section id="bootstrapservers">
<h3>BootstrapServers<a class="headerlink" href="#bootstrapservers" title="Link to this heading">ÔÉÅ</a></h3>
<p>(Required) The Kafka bootstrap servers. This is the same setting that is used by the underlying producer and consumer clients to connect to the Kafka cluster. Example: ‚Äúkafka-broker1:9092,kafka-broker2:9092‚Äù.</p>
<p>Tip:
Kafka Streams applications can only communicate with a single Kafka cluster specified by this config value. Future versions of Kafka Streams will support connecting to different Kafka clusters for reading input streams and writing output stream</p>
</section>
</section>
<section id="optional-configuration-parameters">
<h2>Optional configuration parameters<a class="headerlink" href="#optional-configuration-parameters" title="Link to this heading">ÔÉÅ</a></h2>
<section id="guarantee">
<h3>Guarantee<a class="headerlink" href="#guarantee" title="Link to this heading">ÔÉÅ</a></h3>
<p>The processing guarantee that should be used. Possible values are <code class="docutils literal notranslate"><span class="pre">ProcessingGuarantee.AT_LEAST_ONCE</span></code> (default) and <code class="docutils literal notranslate"><span class="pre">ProcessingGuarantee.EXACTLY_ONCE</span></code>. Note that if exactly-once processing is enabled, the default for parameter commit.interval.ms changes to 100ms. Additionally, consumers are configured with isolation.level=‚Äùread_committed‚Äù and producers are configured with retries=Int32.MAX_VALUE, enable.idempotence=true, and max.in.flight.requests.per.connection=5 per default. Note that by default exactly-once processing requires a cluster of at least three brokers what is the recommended setting for production. For development you can change this, by adjusting broker setting transaction.state.log.replication.factor and transaction.state.log.min.isr to the number of broker you want to use.</p>
</section>
<section id="defaulttimestampextractor">
<h3>DefaultTimestampExtractor<a class="headerlink" href="#defaulttimestampextractor" title="Link to this heading">ÔÉÅ</a></h3>
<p>A timestamp extractor pulls a timestamp from an instance of ConsumeResult. Timestamps are used to control the progress of streams.</p>
<p>The default extractor is FailOnInvalidTimestamp. This extractor retrieves built-in timestamps that are automatically embedded into Kafka messages by the Kafka producer client since Kafka version 0.10. Depending on the setting of Kafka‚Äôs server-side log.message.timestamp.type broker and message.timestamp.type topic parameters, this extractor provides you with:</p>
<p>event-time processing semantics if log.message.timestamp.type is set to CreateTime aka ‚Äúproducer time‚Äù (which is the default). This represents the time when a Kafka producer sent the original message. If you use Kafka‚Äôs official producer client, the timestamp represents milliseconds since the epoch.
ingestion-time processing semantics if log.message.timestamp.type is set to LogAppendTime aka ‚Äúbroker time‚Äù. This represents the time when the Kafka broker received the original message, in milliseconds since the epoch.
The FailOnInvalidTimestamp extractor throws an exception if a record contains an invalid (i.e. negative) built-in timestamp, because Kafka Streams would not process this record but silently drop it. Invalid built-in timestamps can occur for various reasons: if for example, you consume a topic that is written to by pre-0.10 Kafka producer clients or by third-party producer clients that don‚Äôt support the new Kafka 0.10 message format yet; another situation where this may happen is after upgrading your Kafka cluster from 0.9 to 0.10, where all the data that was generated with 0.9 does not include the 0.10 message timestamps.</p>
<p>You can provide your own timestamp extractors, for instance to retrieve timestamps embedded in the payload of messages. If you cannot extract a valid timestamp, you can either throw an exception, return a negative timestamp, or estimate a timestamp.</p>
<p>Returning a negative timestamp will result in data loss ‚Äì the corresponding record will not be processed but silently dropped. If you want to estimate a new timestamp, you can use the value provided via previousTimestamp (i.e., a Kafka Streams timestamp estimation). Here is an example of a custom TimestampExtractor implementation:</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="nn">System</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">Confluent.Kafka</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">Streamiz.Kafka.Net.Crosscutting</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">Streamiz.Kafka.Net.Processors</span><span class="p">;</span>

<span class="k">public</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">public</span><span class="w"> </span><span class="n">DateTime</span><span class="w"> </span><span class="n">dateCreated</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">get</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="k">public</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">Id</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">get</span><span class="p">;</span><span class="w"> </span><span class="k">set</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>

<span class="w">    </span><span class="k">public</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="nf">GetTimestampInMillis</span><span class="p">()</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">dateCreated</span><span class="p">.</span><span class="n">GetMilliseconds</span><span class="p">();</span>
<span class="p">}</span>

<span class="k">public</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">MyExtractor</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">ITimestampExtractor</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">public</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="nf">Extract</span><span class="p">(</span><span class="n">ConsumeResult</span><span class="o">&lt;</span><span class="kt">object</span><span class="p">,</span><span class="w"> </span><span class="kt">object</span><span class="o">&gt;</span><span class="w"> </span><span class="k">record</span><span class="p">,</span><span class="w"> </span><span class="kt">long</span><span class="w"> </span><span class="n">partitionTime</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// `Foo` is your own custom class, which we assume has a method that returns</span>
<span class="w">        </span><span class="c1">// the embedded timestamp (milliseconds since midnight, January 1, 1970 UTC).</span>
<span class="w">        </span><span class="kt">long</span><span class="w"> </span><span class="n">timestamp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
<span class="w">        </span><span class="n">Foo</span><span class="w"> </span><span class="n">myPojo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Foo</span><span class="p">)</span><span class="k">record</span><span class="p">.</span><span class="n">Message</span><span class="p">.</span><span class="n">Value</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myPojo</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="k">null</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="n">timestamp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">myPojo</span><span class="p">.</span><span class="n">GetTimestampInMillis</span><span class="p">();</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">timestamp</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// Invalid timestamp!  Attempt to estimate a new timestamp,</span>
<span class="w">            </span><span class="c1">// otherwise fall back to wall-clock time (processing-time).</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">partitionTime</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">partitionTime</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="k">else</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">DateTime</span><span class="p">.</span><span class="n">Now</span><span class="p">.</span><span class="n">GetMilliseconds</span><span class="p">();</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="k">else</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">timestamp</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>You would then define the custom timestamp extractor in your Streams configuration as follows:</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="k">using</span><span class="w"> </span><span class="nn">Streamiz.Kafka.Net</span><span class="p">;</span>

<span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="p">();</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">DefaultTimestampExtractor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MyExtractor</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="defaultkeyserdes">
<h3>DefaultKeySerDes<a class="headerlink" href="#defaultkeyserdes" title="Link to this heading">ÔÉÅ</a></h3>
<p>The default Serializer/Deserializer class for record keys. Serialization and deserialization in Kafka Streams happens whenever data needs to be materialized, for example:</p>
<p>Whenever data is read from or written to a Kafka topic (e.g., via the StreamsBuilder#Stream&lt;K, V&gt;() and IKStream&lt;K, V&gt;#To() methods).
Whenever data is read from or written to a state store.</p>
<p>Example :</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="p">();</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">DefaultKeySerDes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StringSerDes</span><span class="p">();</span>
</pre></div>
</div>
<p>Note : In Streamiz Kafka Net package, you have a stream configuration class with generic types parameters to set default (key and value) serdes</p>
<p>Example :</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c1">// Set defaultkeyserdes to StringSerDes, and defaultvalueserdes to StringSerDes</span>
<span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="o">&lt;</span><span class="n">StringSerDes</span><span class="p">,</span><span class="w"> </span><span class="n">StringSerDes</span><span class="o">&gt;</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="defaultvalueserdes">
<h3>DefaultValueSerDes<a class="headerlink" href="#defaultvalueserdes" title="Link to this heading">ÔÉÅ</a></h3>
<p>The default Serializer/Deserializer class for record values. Serialization and deserialization in Kafka Streams happens whenever data needs to be materialized, for example:</p>
<p>Whenever data is read from or written to a Kafka topic (e.g., via the StreamsBuilder#Stream&lt;K, V&gt;() and IKStream&lt;K, V&gt;#To() methods).
Whenever data is read from or written to a state store.</p>
<p>Example :</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="p">();</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">DefaultValueSerDes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StringSerDes</span><span class="p">();</span>
</pre></div>
</div>
<p>Note : In Streamiz Kafka Net package, you have a stream configuration class with generic types parameters to set default (key and value) serdes</p>
<p>Example :</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="c1">// Set defaultkeyserdes to StringSerDes, and defaultvalueserdes to StringSerDes</span>
<span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="o">&lt;</span><span class="n">StringSerDes</span><span class="p">,</span><span class="w"> </span><span class="n">StringSerDes</span><span class="o">&gt;</span><span class="p">();</span>
</pre></div>
</div>
</section>
<section id="numstreamthreads">
<h3>NumStreamThreads<a class="headerlink" href="#numstreamthreads" title="Link to this heading">ÔÉÅ</a></h3>
<p>This specifies the number of stream threads in an instance of the Kafka Streams application. The stream processing code runs in these thread.</p>
</section>
<section id="clientid">
<h3>ClientId<a class="headerlink" href="#clientid" title="Link to this heading">ÔÉÅ</a></h3>
<p>An ID prefix string used for the client IDs of internal consumer, producer and restore-consumer, with pattern ‚Äò<ClientId>-StreamThread-<threadSequenceNumber>-&lt;consumer|producer|restore-consumer&gt;‚Äô with</p>
<ul class="simple">
<li><p>ClientId : property setted, if null or empty, CliendId is randomly generated wih ‚ÄòApplicationId-{GUID}‚Äô</p></li>
<li><p>threadSequenceNumber : Thread number</p></li>
</ul>
</section>
<section id="transactionalid">
<h3>TransactionalId<a class="headerlink" href="#transactionalid" title="Link to this heading">ÔÉÅ</a></h3>
<p>Enables the transactional producer. The TransactionalId is used to identify the same transactional producer instance across process restarts.
Only use if Guarantee is setted to <code class="docutils literal notranslate"><span class="pre">ProcessingGuarantee.EXACTLY_ONCE</span></code>.</p>
</section>
<section id="transactiontimeout">
<h3>TransactionTimeout<a class="headerlink" href="#transactiontimeout" title="Link to this heading">ÔÉÅ</a></h3>
<p>Timeout used for transaction related operations. (Default : 10 seconds).
Only use if Guarantee is set to <code class="docutils literal notranslate"><span class="pre">ProcessingGuarantee.EXACTLY_ONCE</span></code>.</p>
</section>
<section id="commitintervalms">
<h3>CommitIntervalMs<a class="headerlink" href="#commitintervalms" title="Link to this heading">ÔÉÅ</a></h3>
<p>The frequency with which to save the position of the processor. (Note, if Guarantee is set to <code class="docutils literal notranslate"><span class="pre">ProcessingGuarantee.EXACTLY_ONCE</span></code>, the default value is <code class="docutils literal notranslate"><span class="pre">StreamConfig.EOS_DEFAULT_COMMIT_INTERVAL_MS</span></code>,
otherwise the default value is <code class="docutils literal notranslate"><span class="pre">StreamConfig.DEFAULT_COMMIT_INTERVAL_MS</span></code>.</p>
</section>
<section id="pollms">
<h3>PollMs<a class="headerlink" href="#pollms" title="Link to this heading">ÔÉÅ</a></h3>
<p>The amount of time in milliseconds to block waiting for input. (Default : 100)</p>
</section>
<section id="maxpollrecords">
<h3>MaxPollRecords<a class="headerlink" href="#maxpollrecords" title="Link to this heading">ÔÉÅ</a></h3>
<p>The maximum number of records returned in consumption processing by thread. (Default: 500)</p>
</section>
<section id="maxpollrestoringrecords">
<h3>MaxPollRestoringRecords<a class="headerlink" href="#maxpollrestoringrecords" title="Link to this heading">ÔÉÅ</a></h3>
<p>The maximum number of records processed for each restoration step. Only use when application needs to restore state store from changelog topics. (Default: 1000)</p>
</section>
<section id="maxtaskidlems">
<h3>MaxTaskIdleMs<a class="headerlink" href="#maxtaskidlems" title="Link to this heading">ÔÉÅ</a></h3>
<p>Maximum amount of time a stream task will stay idle when not all of its partition buffers contain records, to avoid potential out-of-order record processing across multiple input streams. (Default: 0)</p>
</section>
<section id="maxpollintervalms">
<h3>MaxPollIntervalMs<a class="headerlink" href="#maxpollintervalms" title="Link to this heading">ÔÉÅ</a></h3>
<p>Maximum allowed time between calls to consume messages for high-level consumers. If this interval is exceeded the consumer is considered failed and the group will rebalance in order to reassign the partitions to another consumer group member.</p>
</section>
<section id="bufferedrecordsperpartition">
<h3>BufferedRecordsPerPartition<a class="headerlink" href="#bufferedrecordsperpartition" title="Link to this heading">ÔÉÅ</a></h3>
<p>[Deprecated] Maximum number of records to buffer per partition. (Default: Int32.MaxValue)
If this number is exceeded, the consumer pauses for this partition until stream instance process messages.</p>
</section>
<section id="innerexceptionhandler">
<h3>InnerExceptionHandler<a class="headerlink" href="#innerexceptionhandler" title="Link to this heading">ÔÉÅ</a></h3>
<p>Inner exception handling function called during processing.</p>
</section>
<section id="deserializationexceptionhandler">
<h3>DeserializationExceptionHandler<a class="headerlink" href="#deserializationexceptionhandler" title="Link to this heading">ÔÉÅ</a></h3>
<p>Deserialization exception handling function called when deserialization exception during kafka consumption is raise.</p>
</section>
<section id="productionexceptionhandler">
<h3>ProductionExceptionHandler<a class="headerlink" href="#productionexceptionhandler" title="Link to this heading">ÔÉÅ</a></h3>
<p>Production exception handling function called when kafka produce exception is raise.</p>
</section>
<section id="logger">
<h3>Logger<a class="headerlink" href="#logger" title="Link to this heading">ÔÉÅ</a></h3>
<p>This library uses Microsoft.Extensions.Logging.Abstractions for logging. To set logging for this library you need to set Logger property in your stream config instance.</p>
<section id="configuring-log4net">
<h4>Configuring log4net<a class="headerlink" href="#configuring-log4net" title="Link to this heading">ÔÉÅ</a></h4>
<p>To configure log4net you need to install Microsoft.Extensions.Logging.Log4Net.AspNetCore nuget package in your project and add log4net.config.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dotnet<span class="w"> </span>add<span class="w"> </span>package<span class="w"> </span>Microsoft.Extensions.Logging.Log4Net.AspNetCore
</pre></div>
</div>
<p>Configure your logger inside your streams config instance :</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamsConfig</span><span class="p">();</span>
<span class="c1">// .... //</span>
<span class="n">config</span><span class="p">.</span><span class="n">Logger</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LoggerFactory</span><span class="p">.</span><span class="n">Create</span><span class="p">(</span><span class="n">builder</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">AddLog4Net</span><span class="p">());</span>
</pre></div>
</div>
<p>Add a log4net.config resources in your project :</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;log4net</span><span class="w"> </span><span class="na">debug=</span><span class="s">&quot;true&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;appender</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;ConsoleAppender&quot;</span><span class="w"> </span><span class="na">type=</span><span class="s">&quot;log4net.Appender.ConsoleAppender&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;param</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;Threshold&quot;</span><span class="w"> </span><span class="na">value=</span><span class="s">&quot;DEBUG&quot;</span><span class="w"> </span><span class="nt">/&gt;</span>
<span class="w">        </span><span class="nt">&lt;layout</span><span class="w"> </span><span class="na">type=</span><span class="s">&quot;log4net.Layout.PatternLayout&quot;</span><span class="nt">&gt;</span>
<span class="w">            </span><span class="nt">&lt;param</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;ConversionPattern&quot;</span><span class="w"> </span><span class="na">value=</span><span class="s">&quot;%d [%t] %-5p %c - %m%n&quot;</span><span class="w"> </span><span class="nt">/&gt;</span>
<span class="w">        </span><span class="nt">&lt;/layout&gt;</span>
<span class="w">    </span><span class="nt">&lt;/appender&gt;</span>
<span class="w">    </span><span class="nt">&lt;root&gt;</span>
<span class="w">        </span><span class="nt">&lt;level</span><span class="w"> </span><span class="na">value=</span><span class="s">&quot;DEBUG&quot;</span><span class="w"> </span><span class="nt">/&gt;</span>
<span class="w">        </span><span class="nt">&lt;appender-ref</span><span class="w"> </span><span class="na">ref=</span><span class="s">&quot;ConsoleAppender&quot;</span><span class="w"> </span><span class="nt">/&gt;</span>
<span class="w">    </span><span class="nt">&lt;/root&gt;</span>
<span class="nt">&lt;/log4net&gt;</span>
</pre></div>
</div>
</section>
</section>
<section id="followmetadata">
<h3>FollowMetadata<a class="headerlink" href="#followmetadata" title="Link to this heading">ÔÉÅ</a></h3>
<p>Authorize your streams application to follow metadata (timestamp, topic, partition, offset and headers) during processing record. You can use <code class="docutils literal notranslate"><span class="pre">StreamizMetadata</span></code> to get these metadatas. (Default : false)</p>
</section>
<section id="statedir">
<h3>StateDir<a class="headerlink" href="#statedir" title="Link to this heading">ÔÉÅ</a></h3>
<p>Directory location for state store. This path must be unique for each streams instance sharing the same underlying filesystem. (Default : <code class="docutils literal notranslate"><span class="pre">Path.Combine(Path.GetTempPath(),</span> <span class="pre">&quot;streamiz-kafka-net&quot;)</span></code>)</p>
</section>
<section id="replicationfactor">
<h3>ReplicationFactor<a class="headerlink" href="#replicationfactor" title="Link to this heading">ÔÉÅ</a></h3>
<p>The replication factor for change log topics topics created by the stream processing application. Default is 1.</p>
</section>
<section id="windowstorechangelogadditionalretentionms">
<h3>WindowStoreChangelogAdditionalRetentionMs<a class="headerlink" href="#windowstorechangelogadditionalretentionms" title="Link to this heading">ÔÉÅ</a></h3>
<p>Added to a windows maintainMs to ensure data is not deleted from the log prematurely. Allows for clock drift.
Default is 1 day.</p>
</section>
<section id="offsetcheckpointmanager">
<h3>OffsetCheckpointManager<a class="headerlink" href="#offsetcheckpointmanager" title="Link to this heading">ÔÉÅ</a></h3>
<p>Manager which track offset saved in local state store.</p>
</section>
<section id="rocksdbconfighandler">
<h3>RocksDbConfigHandler<a class="headerlink" href="#rocksdbconfighandler" title="Link to this heading">ÔÉÅ</a></h3>
<p>A Rocks DB config handler function called just before openning a rocksdb state store.</p>
</section>
<section id="metricsintervalms">
<h3>MetricsIntervalMs<a class="headerlink" href="#metricsintervalms" title="Link to this heading">ÔÉÅ</a></h3>
<p>Delay between two invocations of <code class="docutils literal notranslate"><span class="pre">MetricsReporter()</span></code>. The minimum and default value is 30 seconds.</p>
</section>
<section id="metricsreporter">
<h3>MetricsReporter<a class="headerlink" href="#metricsreporter" title="Link to this heading">ÔÉÅ</a></h3>
<p>The reporter expose a list of sensors throw by a stream thread every <code class="docutils literal notranslate"><span class="pre">MetricsIntervalMs</span></code> This reporter has the responsibility to export sensors and metrics into another platform (default: empty).</p>
<p>Streamiz provide multiple reporters (see <code class="docutils literal notranslate"><span class="pre">Streamiz.Kafka.Net.Metrics.Prometheus</span></code> and <code class="docutils literal notranslate"><span class="pre">Streamiz.Kafka.Net.Metrics.OpenTelemetry</span></code>). You can easily implement your own reporter and publish your metrics inside one another system.</p>
</section>
<section id="exposelibrdkafkastats">
<h3>ExposeLibrdKafkaStats<a class="headerlink" href="#exposelibrdkafkastats" title="Link to this heading">ÔÉÅ</a></h3>
<p>Boolean which indicate if librdkafka handle statistics should be exposed ot not (default: false).
<strong>Only main consumer and producer will be concerned.</strong></p>
</section>
<section id="metricsrecording">
<h3>MetricsRecording<a class="headerlink" href="#metricsrecording" title="Link to this heading">ÔÉÅ</a></h3>
<p>The highest recording level for metrics (default: INFO).</p>
</section>
<section id="starttaskdelayms">
<h3>StartTaskDelayMs<a class="headerlink" href="#starttaskdelayms" title="Link to this heading">ÔÉÅ</a></h3>
<p>[Obsolete] Time wait before completing the start task of <code class="docutils literal notranslate"><span class="pre">KafkaStream</span></code> (default: 5000).</p>
</section>
<section id="basicauthuserinfo">
<h3>BasicAuthUserInfo<a class="headerlink" href="#basicauthuserinfo" title="Link to this heading">ÔÉÅ</a></h3>
<p>Credentials for the schema registry</p>
</section>
<section id="basicauthcredentialssource">
<h3>BasicAuthCredentialsSource<a class="headerlink" href="#basicauthcredentialssource" title="Link to this heading">ÔÉÅ</a></h3>
<p>Specifies the source, use 0 for UserInfo or 1 for SaslInherit.</p>
</section>
<section id="schemaregistryrequesttimeoutms">
<h3>SchemaRegistryRequestTimeoutMs<a class="headerlink" href="#schemaregistryrequesttimeoutms" title="Link to this heading">ÔÉÅ</a></h3>
<p>Specifies the timeout for requests to Confluent Schema Registry.
Default: 30000</p>
</section>
<section id="schemaregistrymaxcachedschemas">
<h3>SchemaRegistryMaxCachedSchemas<a class="headerlink" href="#schemaregistrymaxcachedschemas" title="Link to this heading">ÔÉÅ</a></h3>
<p>Specifies the maximum number of schemas CachedSchemaRegistryClient should cache locally.
Default: 1000</p>
</section>
<section id="schemaregistryurl">
<h3>SchemaRegistryUrl<a class="headerlink" href="#schemaregistryurl" title="Link to this heading">ÔÉÅ</a></h3>
<p>A comma-separated list of URLs for schema registry instances that are used register or lookup schemas.</p>
</section>
<section id="autoregisterschemas">
<h3>AutoRegisterSchemas<a class="headerlink" href="#autoregisterschemas" title="Link to this heading">ÔÉÅ</a></h3>
<p>Specifies whether or not the Avro serializer should attempt to auto-register unrecognized schemas with Confluent Schema Registry.
Default: true</p>
</section>
<section id="subjectnamestrategy">
<h3>SubjectNameStrategy<a class="headerlink" href="#subjectnamestrategy" title="Link to this heading">ÔÉÅ</a></h3>
<p>The subject name strategy to use for schema registration / lookup.
Possible values: <code class="docutils literal notranslate"><span class="pre">Topic,</span> <span class="pre">Record,</span> <span class="pre">TopicRecord</span></code></p>
</section>
</section>
<section id="kafka-consumers-and-producer-configuration-parameters">
<h2>Kafka consumers and producer configuration parameters<a class="headerlink" href="#kafka-consumers-and-producer-configuration-parameters" title="Link to this heading">ÔÉÅ</a></h2>
<p>You can specify parameters for the Kafka consumers, producers, and admin client that are used internally. The consumer, producer and admin client settings are defined by wrapper properties on ConsumerConfig, ProducerConfig and AdminConfig.</p>
<p>So, all consumer, producer and admin client settings are accessible directly from StreamConfig instance.</p>
<p>In this example, the Kafka consumer session timeout is configured to be 60000 milliseconds in the StreamConfig instance.</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="p">();</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SessionTimeoutMs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">60000</span><span class="p">;</span>
</pre></div>
</div>
<p>In case of the configuration is not wrapped in StreamConfig yet or because you want to override differnetly the configuration of the main consumer and the configuration of the restore consumer , you can directly add your configuration via the following methods.</p>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// add key/value for the main consumer (prefix : &quot;main.consumer.&quot;), similar to config.Add(&quot;main.consumer.fetch.min.bytes&quot;, 1000);</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">StreamConfig</span><span class="p">.</span><span class="n">MainConsumerPrefix</span><span class="p">(</span><span class="s">&quot;fetch.min.bytes&quot;</span><span class="p">),</span><span class="w"> </span><span class="mi">1000</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// add key/value for the restore consumer (prefix : &quot;restore.consumer.&quot;), similar to config.Add(&quot;restore.consumer.fetch.max.bytes&quot;, 1000000);</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">StreamConfig</span><span class="p">.</span><span class="n">RestoreConsumerPrefix</span><span class="p">(</span><span class="s">&quot;fetch.max.bytes&quot;</span><span class="p">),</span><span class="w"> </span><span class="mi">1000000</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// add key/value for the global consumer (prefix : &quot;global.consumer.&quot;), similar to config.Add(&quot;global.consumer.fetch.max.bytes&quot;, 1000000);</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">StreamConfig</span><span class="p">.</span><span class="n">GlobalConsumerPrefix</span><span class="p">(</span><span class="s">&quot;fetch.max.bytes&quot;</span><span class="p">),</span><span class="w"> </span><span class="mi">1000000</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// add key/value for the producer (prefix : &quot;producer.&quot;), similar to config.Add(&quot;producer.acks&quot;, Acks.All);</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">StreamConfig</span><span class="p">.</span><span class="n">ProducerPrefix</span><span class="p">(</span><span class="s">&quot;acks&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">Acks</span><span class="p">.</span><span class="n">All</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="sample-configuration-implementation">
<h2>Sample configuration implementation<a class="headerlink" href="#sample-configuration-implementation" title="Link to this heading">ÔÉÅ</a></h2>
<div class="highlight-csharp notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">var</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">StreamConfig</span><span class="o">&lt;</span><span class="n">StringSerDes</span><span class="p">,</span><span class="w"> </span><span class="n">StringSerDes</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">ApplicationId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;test-app&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">BootstrapServers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;192.168.56.1:9092&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SaslMechanism</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SaslMechanism</span><span class="p">.</span><span class="n">Plain</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SaslUsername</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;admin&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SaslPassword</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;admin&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SecurityProtocol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SecurityProtocol</span><span class="p">.</span><span class="n">SaslPlaintext</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">AutoOffsetReset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AutoOffsetReset</span><span class="p">.</span><span class="n">Earliest</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">NumStreamThreads</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">SchemaRegistryUrl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;http://localhost:8081&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">BasicAuthUserInfo</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;user:password&quot;</span><span class="p">;</span>
<span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">BasicAuthCredentialsSource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="overview.html" class="btn btn-neutral float-left" title="Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="threading-model.html" class="btn btn-neutral float-right" title="Threading model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, @LGouellec.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>